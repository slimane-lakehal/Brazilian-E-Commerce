{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334e2c98",
   "metadata": {},
   "source": [
    "3.1 Pricing Strategy A/B Test Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd630176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for statistical testing\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "import random\n",
    "\n",
    "# Simulate an A/B test for pricing strategies\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to simulate customer behavior under different pricing\n",
    "def simulate_customer_behavior(price, base_conversion_rate=0.05, price_elasticity=-0.005):\n",
    "    # Conversion rate decreases as price increases\n",
    "    conversion_rate = base_conversion_rate + price_elasticity * (price - 100)\n",
    "    # Ensure conversion rate is between 0 and 1\n",
    "    conversion_rate = max(0.01, min(0.2, conversion_rate))\n",
    "    # Simulate conversion (1 = purchase, 0 = no purchase)\n",
    "    return np.random.binomial(1, conversion_rate)\n",
    "\n",
    "# Set up the experiment\n",
    "control_price = 100  # Original price\n",
    "treatment_price = 90  # Discounted price\n",
    "\n",
    "# Sample size calculation\n",
    "effect_size = 0.1  # Expected effect size (10% increase in conversion)\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Statistical power\n",
    "\n",
    "# Calculate required sample size\n",
    "power_analysis = TTestIndPower()\n",
    "sample_size = power_analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "sample_size = int(np.ceil(sample_size))\n",
    "\n",
    "print(f\"Required sample size per group: {sample_size}\")\n",
    "\n",
    "# Simulate the experiment with a larger sample for demonstration\n",
    "sample_size = max(sample_size, 1000)\n",
    "total_customers = sample_size * 2\n",
    "\n",
    "# Create experiment data\n",
    "experiment_data = pd.DataFrame({\n",
    "    'customer_id': range(total_customers),\n",
    "    'group': ['control' if i < sample_size else 'treatment' for i in range(total_customers)]\n",
    "})\n",
    "\n",
    "# Apply pricing and simulate conversions\n",
    "experiment_data['price'] = experiment_data['group'].map({'control': control_price, 'treatment': treatment_price})\n",
    "experiment_data['converted'] = experiment_data.apply(\n",
    "    lambda row: simulate_customer_behavior(row['price']), axis=1\n",
    ")\n",
    "\n",
    "# Calculate revenue\n",
    "experiment_data['revenue'] = experiment_data['converted'] * experiment_data['price']\n",
    "\n",
    "# Analyze results\n",
    "results_by_group = experiment_data.groupby('group').agg({\n",
    "    'customer_id': 'count',\n",
    "    'converted': ['sum', 'mean'],\n",
    "    'revenue': ['sum', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "results_by_group.columns = ['group', 'customers', 'conversions', 'conversion_rate', 'total_revenue', 'average_revenue']\n",
    "\n",
    "print(\"\\nA/B Test Results:\")\n",
    "display(results_by_group)\n",
    "\n",
    "# Statistical testing for conversion rate\n",
    "control_conversions = experiment_data[experiment_data['group'] == 'control']['converted']\n",
    "treatment_conversions = experiment_data[experiment_data['group'] == 'treatment']['converted']\n",
    "\n",
    "# Chi-square test for conversion rates\n",
    "contingency_table = pd.crosstab(experiment_data['group'], experiment_data['converted'])\n",
    "chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\nChi-square test for conversion rates:\")\n",
    "print(f\"Chi2 value: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Statistically significant difference: {p_value < alpha}\")\n",
    "\n",
    "# T-test for revenue\n",
    "t_stat, p_value_revenue = stats.ttest_ind(\n",
    "    experiment_data[experiment_data['group'] == 'control']['revenue'],\n",
    "    experiment_data[experiment_data['group'] == 'treatment']['revenue']\n",
    ")\n",
    "\n",
    "print(f\"\\nT-test for revenue:\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value_revenue:.4f}\")\n",
    "print(f\"Statistically significant difference: {p_value_revenue < alpha}\")\n",
    "\n",
    "# Calculate effect sizes\n",
    "control_conv_rate = results_by_group[results_by_group['group'] == 'control']['conversion_rate'].values[0]\n",
    "treatment_conv_rate = results_by_group[results_by_group['group'] == 'treatment']['conversion_rate'].values[0]\n",
    "relative_lift_conv = (treatment_conv_rate - control_conv_rate) / control_conv_rate * 100\n",
    "\n",
    "control_revenue = results_by_group[results_by_group['group'] == 'control']['total_revenue'].values[0]\n",
    "treatment_revenue = results_by_group[results_by_group['group'] == 'treatment']['total_revenue'].values[0]\n",
    "relative_lift_revenue = (treatment_revenue - control_revenue) / control_revenue * 100\n",
    "\n",
    "print(f\"\\nRelative lift in conversion rate: {relative_lift_conv:.2f}%\")\n",
    "print(f\"Relative lift in total revenue: {relative_lift_revenue:.2f}%\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='group', y='conversion_rate', data=results_by_group, palette='viridis')\n",
    "plt.title('Conversion Rate by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Conversion Rate')\n",
    "plt.ylim(0, max(results_by_group['conversion_rate']) * 1.2)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='group', y='total_revenue', data=results_by_group, palette='viridis')\n",
    "plt.title('Total Revenue by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.ylim(0, max(results_by_group['total_revenue']) * 1.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPricing strategy A/B test simulation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf6964",
   "metadata": {},
   "source": [
    "3.2 Delivery Options A/B Test Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate an A/B test for different delivery options\n",
    "np.random.seed(43)\n",
    "\n",
    "# Function to simulate customer satisfaction based on delivery time\n",
    "def simulate_satisfaction(delivery_time, expected_time=15):\n",
    "    # Base satisfaction score (1-5)\n",
    "    base_score = 4.0\n",
    "    \n",
    "    # Adjust based on delivery time relative to expectation\n",
    "    time_factor = (expected_time - delivery_time) / expected_time\n",
    "    \n",
    "    # Add some random noise\n",
    "    noise = np.random.normal(0, 0.5)\n",
    "    \n",
    "    # Calculate final score\n",
    "    score = base_score + time_factor + noise\n",
    "    \n",
    "    # Ensure score is between 1 and 5\n",
    "    return max(1, min(5, score))\n",
    "\n",
    "# Set up the experiment\n",
    "control_delivery = 'Standard'  # 5-15 days\n",
    "treatment_delivery = 'Express'  # 2-7 days\n",
    "\n",
    "# Simulate delivery times\n",
    "def get_delivery_time(delivery_option):\n",
    "    if delivery_option == 'Standard':\n",
    "        return np.random.randint(5, 16)  # 5-15 days\n",
    "    else:  # Express\n",
    "        return np.random.randint(2, 8)   # 2-7 days\n",
    "\n",
    "# Create experiment data\n",
    "sample_size = 500  # per group\n",
    "total_customers = sample_size * 2\n",
    "\n",
    "delivery_experiment = pd.DataFrame({\n",
    "    'customer_id': range(total_customers),\n",
    "    'group': ['control' if i < sample_size else 'treatment' for i in range(total_customers)]\n",
    "})\n",
    "\n",
    "# Apply delivery options\n",
    "delivery_experiment['delivery_option'] = delivery_experiment['group'].map({\n",
    "    'control': control_delivery, \n",
    "    'treatment': treatment_delivery\n",
    "})\n",
    "\n",
    "# Simulate delivery times and satisfaction\n",
    "delivery_experiment['delivery_time'] = delivery_experiment['delivery_option'].apply(get_delivery_time)\n",
    "delivery_experiment['satisfaction'] = delivery_experiment['delivery_time'].apply(simulate_satisfaction)\n",
    "\n",
    "# Add cost information\n",
    "delivery_experiment['delivery_cost'] = delivery_experiment['delivery_option'].map({\n",
    "    'Standard': 10, \n",
    "    'Express': 20\n",
    "})\n",
    "\n",
    "# Analyze results\n",
    "delivery_results = delivery_experiment.groupby('group').agg({\n",
    "    'customer_id': 'count',\n",
    "    'delivery_time': ['mean', 'std'],\n",
    "    'satisfaction': ['mean', 'std'],\n",
    "    'delivery_cost': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns\n",
    "delivery_results.columns = ['group', 'customers', 'avg_delivery_time', 'std_delivery_time', \n",
    "                           'avg_satisfaction', 'std_satisfaction', 'avg_delivery_cost']\n",
    "\n",
    "print(\"\\nDelivery Options A/B Test Results:\")\n",
    "display(delivery_results)\n",
    "\n",
    "# Statistical testing for satisfaction scores\n",
    "control_satisfaction = delivery_experiment[delivery_experiment['group'] == 'control']['satisfaction']\n",
    "treatment_satisfaction = delivery_experiment[delivery_experiment['group'] == 'treatment']['satisfaction']\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(control_satisfaction, treatment_satisfaction)\n",
    "\n",
    "print(f\"\\nT-test for satisfaction scores:\")\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Statistically significant difference: {p_value < 0.05}\")\n",
    "\n",
    "# Calculate effect size (Cohen's d)\n",
    "cohens_d = (treatment_satisfaction.mean() - control_satisfaction.mean()) / np.sqrt(\n",
    "    (treatment_satisfaction.std() ** 2 + control_satisfaction.std() ** 2) / 2\n",
    ")\n",
    "\n",
    "print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "\n",
    "# Cost-benefit analysis\n",
    "avg_control_satisfaction = delivery_results[delivery_results['group'] == 'control']['avg_satisfaction'].values[0]\n",
    "avg_treatment_satisfaction = delivery_results[delivery_results['group'] == 'treatment']['avg_satisfaction'].values[0]\n",
    "satisfaction_improvement = avg_treatment_satisfaction - avg_control_satisfaction\n",
    "\n",
    "control_cost = delivery_results[delivery_results['group'] == 'control']['avg_delivery_cost'].values[0]\n",
    "treatment_cost = delivery_results[delivery_results['group'] == 'treatment']['avg_delivery_cost'].values[0]\n",
    "cost_increase = treatment_cost - control_cost\n",
    "\n",
    "cost_per_satisfaction_point = cost_increase / satisfaction_improvement if satisfaction_improvement > 0 else float('inf')\n",
    "\n",
    "print(f\"\\nCost-benefit analysis:\")\n",
    "print(f\"Satisfaction improvement: {satisfaction_improvement:.2f} points\")\n",
    "print(f\"Cost increase: ${cost_increase:.2f}\")\n",
    "print(f\"Cost per satisfaction point: ${cost_per_satisfaction_point:.2f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='group', y='delivery_time', data=delivery_experiment, palette='viridis')\n",
    "plt.title('Delivery Time by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Delivery Time (days)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x='group', y='satisfaction', data=delivery_experiment, palette='viridis')\n",
    "plt.title('Customer Satisfaction by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Satisfaction Score (1-5)')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.scatterplot(x='delivery_time', y='satisfaction', hue='group', data=delivery_experiment, palette='viridis')\n",
    "plt.title('Satisfaction vs. Delivery Time')\n",
    "plt.xlabel('Delivery Time (days)')\n",
    "plt.ylabel('Satisfaction Score (1-5)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='group', y='avg_delivery_cost', data=delivery_results, palette='viridis')\n",
    "plt.title('Average Delivery Cost by Group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Average Cost ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDelivery options A/B test simulation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceee7ba",
   "metadata": {},
   "source": [
    "3.3 A/B Testing Framework Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2307692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a general A/B testing framework\n",
    "class ABTestFramework:\n",
    "    def __init__(self, name, metric_name, alpha=0.05, power=0.8, effect_size=0.1):\n",
    "        self.name = name\n",
    "        self.metric_name = metric_name\n",
    "        self.alpha = alpha\n",
    "        self.power = power\n",
    "        self.effect_size = effect_size\n",
    "        self.control_data = []\n",
    "        self.treatment_data = []\n",
    "        \n",
    "    def calculate_sample_size(self):\n",
    "        \"\"\"Calculate required sample size per group\"\"\"\n",
    "        power_analysis = TTestIndPower()\n",
    "        sample_size = power_analysis.solve_power(\n",
    "            effect_size=self.effect_size, \n",
    "            power=self.power, \n",
    "            alpha=self.alpha\n",
    "        )\n",
    "        return int(np.ceil(sample_size))\n",
    "    \n",
    "    def add_data(self, group, value):\n",
    "        \"\"\"Add observation to the appropriate group\"\"\"\n",
    "        if group == 'control':\n",
    "            self.control_data.append(value)\n",
    "        elif group == 'treatment':\n",
    "            self.treatment_data.append(value)\n",
    "        else:\n",
    "            raise ValueError(\"Group must be 'control' or 'treatment'\")\n",
    "    \n",
    "    def get_summary_stats(self):\n",
    "        \"\"\"Calculate summary statistics for both groups\"\"\"\n",
    "        control_mean = np.mean(self.control_data) if self.control_data else 0\n",
    "        treatment_mean = np.mean(self.treatment_data) if self.treatment_data else 0\n",
    "        control_std = np.std(self.control_data) if len(self.control_data) > 1 else 0\n",
    "        treatment_std = np.std(self.treatment_data) if len(self.treatment_data) > 1 else 0\n",
    "        \n",
    "        return {\n",
    "            'control_n': len(self.control_data),\n",
    "            'treatment_n': len(self.treatment_data),\n",
    "            'control_mean': control_mean,\n",
    "            'treatment_mean': treatment_mean,\n",
    "            'control_std': control_std,\n",
    "            'treatment_std': treatment_std,\n",
    "            'absolute_difference': treatment_mean - control_mean,\n",
    "            'relative_difference': ((treatment_mean - control_mean) / control_mean * 100) if control_mean != 0 else 0\n",
    "        }\n",
    "    \n",
    "    def run_t_test(self):\n",
    "        \"\"\"Run t-test to compare means\"\"\"\n",
    "        if len(self.control_data) < 2 or len(self.treatment_data) < 2:\n",
    "            return None, None\n",
    "        \n",
    "        t_stat, p_value = stats.ttest_ind(self.control_data, self.treatment_data)\n",
    "        significant = p_value < self.alpha\n",
    "        \n",
    "        return {\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': significant\n",
    "        }\n",
    "    \n",
    "    def calculate_effect_size(self):\n",
    "        \"\"\"Calculate Cohen's d effect size\"\"\"\n",
    "        if len(self.control_data) < 2 or len(self.treatment_data) < 2:\n",
    "            return None\n",
    "        \n",
    "        control_mean = np.mean(self.control_data)\n",
    "        treatment_mean = np.mean(self.treatment_data)\n",
    "        control_std = np.std(self.control_data)\n",
    "        treatment_std = np.std(self.treatment_data)\n",
    "        \n",
    "        # Pooled standard deviation\n",
    "        pooled_std = np.sqrt((control_std**2 + treatment_std**2) / 2)\n",
    "        \n",
    "        # Cohen's d\n",
    "        d = (treatment_mean - control_mean) / pooled_std if pooled_std != 0 else 0\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Get complete test results\"\"\"\n",
    "        summary = self.get_summary_stats()\n",
    "        t_test = self.run_t_test()\n",
    "        effect_size = self.calculate_effect_size()\n",
    "        \n",
    "        required_sample = self.calculate_sample_size()\n",
    "        has_enough_data = (summary['control_n'] >= required_sample and \n",
    "                          summary['treatment_n'] >= required_sample)\n",
    "        \n",
    "        return {\n",
    "            'test_name': self.name,\n",
    "            'metric': self.metric_name,\n",
    "            'summary': summary,\n",
    "            't_test': t_test,\n",
    "            'effect_size': effect_size,\n",
    "            'required_sample_size': required_sample,\n",
    "            'has_enough_data': has_enough_data\n",
    "        }\n",
    "    \n",
    "    def visualize_results(self):\n",
    "        \"\"\"Visualize test results\"\"\"\n",
    "        results = self.get_results()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot means with error bars\n",
    "        plt.subplot(2, 2, 1)\n",
    "        groups = ['Control', 'Treatment']\n",
    "        means = [results['summary']['control_mean'], results['summary']['treatment_mean']]\n",
    "        errors = [results['summary']['control_std'] / np.sqrt(results['summary']['control_n']) if results['summary']['control_n'] > 0 else 0,\n",
    "                 results['summary']['treatment_std'] / np.sqrt(results['summary']['treatment_n']) if results['summary']['treatment_n'] > 0 else 0]\n",
    "        \n",
    "        plt.bar(groups, means, yerr=errors, capsize=10, color=['#1f77b4', '#ff7f0e'])\n",
    "        plt.title(f'{self.metric_name} by Group')\n",
    "        plt.ylabel(self.metric_name)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Plot distributions\n",
    "        plt.subplot(2, 2, 2)\n",
    "        if self.control_data and self.treatment_data:\n",
    "            sns.kdeplot(self.control_data, label='Control', shade=True)\n",
    "            sns.kdeplot(self.treatment_data, label='Treatment', shade=True)\n",
    "            plt.title(f'Distribution of {self.metric_name}')\n",
    "            plt.xlabel(self.metric_name)\n",
    "            plt.ylabel('Density')\n",
    "            plt.legend()\n",
    "        \n",
    "        # Plot sample size vs. required\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sample_sizes = [results['summary']['control_n'], results['summary']['treatment_n']]\n",
    "        required = results['required_sample_size']\n",
    "        \n",
    "        bars = plt.bar(groups, sample_sizes, color=['#1f77b4', '#ff7f0e'])\n",
    "        plt.axhline(y=required, color='r', linestyle='--', label=f'Required ({required})')\n",
    "        \n",
    "        # Color bars based on whether they meet the requirement\n",
    "        for i, bar in enumerate(bars):\n",
    "            if sample_sizes[i] < required:\n",
    "                bar.set_color('#d62728')  # Red for insufficient\n",
    "        \n",
    "        plt.title('Sample Size vs. Required')\n",
    "        plt.ylabel('Sample Size')\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Plot p-value\n",
    "        plt.subplot(2, 2, 4)\n",
    "        if results['t_test'] and 'p_value' in results['t_test']:\n",
    "            p_value = results['t_test']['p_value']\n",
    "            plt.bar(['p-value'], [p_value], color='g' if p_value < self.alpha else 'r')\n",
    "            plt.axhline(y=self.alpha, color='r', linestyle='--', label=f'Alpha ({self.alpha})')\n",
    "            plt.title('Statistical Significance')\n",
    "            plt.ylabel('p-value')\n",
    "            plt.ylim(0, min(1, p_value * 2) if p_value > 0 else 1)\n",
    "            plt.legend()\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'A/B Test Results: {self.name}', fontsize=16)\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"A/B Test: {self.name}\")\n",
    "        print(f\"Metric: {self.metric_name}\")\n",
    "        print(f\"Control: {results['summary']['control_mean']:.4f} ± {results['summary']['control_std']:.4f} (n={results['summary']['control_n']})\")\n",
    "        print(f\"Treatment: {results['summary']['treatment_mean']:.4f} ± {results['summary']['treatment_std']:.4f} (n={results['summary']['treatment_n']})\")\n",
    "        print(f\"Absolute difference: {results['summary']['absolute_difference']:.4f}\")\n",
    "        print(f\"Relative difference: {results['summary']['relative_difference']:.2f}%\")\n",
    "        \n",
    "        if results['t_test'] and 'p_value' in results['t_test']:\n",
    "            print(f\"p-value: {results['t_test']['p_value']:.4f}\")\n",
    "            print(f\"Statistically significant: {results['t_test']['significant']}\")\n",
    "        \n",
    "        if results['effect_size'] is not None:\n",
    "            print(f\"Effect size (Cohen's d): {results['effect_size']:.4f}\")\n",
    "        \n",
    "        print(f\"Required sample size per group: {results['required_sample_size']}\")\n",
    "        print(f\"Has enough data: {results['has_enough_data']}\")\n",
    "\n",
    "# Demonstrate the framework with a simulated promotion test\n",
    "promotion_test = ABTestFramework(\n",
    "    name=\"10% Discount Promotion\",\n",
    "    metric_name=\"Conversion Rate\",\n",
    "    effect_size=0.1,\n",
    "    alpha=0.05,\n",
    "    power=0.8\n",
    ")\n",
    "\n",
    "# Simulate data\n",
    "np.random.seed(44)\n",
    "\n",
    "# Control group (no promotion)\n",
    "control_conversion_rate = 0.05\n",
    "for _ in range(1000):\n",
    "    conversion = np.random.binomial(1, control_conversion_rate)\n",
    "    promotion_test.add_data('control', conversion)\n",
    "\n",
    "# Treatment group (with promotion)\n",
    "treatment_conversion_rate = 0.07  # Expected 40% lift\n",
    "for _ in range(1000):\n",
    "    conversion = np.random.binomial(1, treatment_conversion_rate)\n",
    "    promotion_test.add_data('treatment', conversion)\n",
    "\n",
    "# Get and visualize results\n",
    "promotion_test.visualize_results()\n",
    "\n",
    "print(\"\\nA/B testing framework implementation complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
